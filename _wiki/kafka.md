---
layout  : wiki
title   : kafka
summary : kafka study
date    : 2020-06-11T18:14:13+0900
updated : 2020-06-18 09:35:22 +0900
tag     : kafka
toc     : true
public  : false
parent  : [[programming]]
latex   : false
comment : true
---
* TOC
{:toc}

## Kafka 톺아보기 

스프링이 제공하는 컴포넌트들이 너무 편해서 카프카를 일단 붙여서 쓰고 있는 중이다. 그런데 너무 덮어놓고 쓰는 느낌이라 책을 찾아보면서 이해해보려고 한다.

## 카프카의 핵심 개념 
- 대규모 처리를 위해 클러스터에 데이터를 분산하는 방법
- 분산 데이터를 함께 그룹 짓기 위한 키/값 쌍과 파티션 사용
- 실패를 피하는 대신 복제를 사용해 실패를 수용

## 스트림 처리 Stream processing 정의 
스트림 처리가 처리할 데이터를 수집하거나 저장할 필요 없이 무한한 데이터 스트림을 유입되는대로 연속으로 처리하는 것

## 카프카는 분산 로그다

- 분산로그라는 점이 대용량 데이터 처리를 가능하게 하는 비결.
- 카프카 메시지는 파티션으로 분산되어 별개의 머신에 저장되지만 데이터 중복을 제공한다.
- 파티션 간의 메시지 순서는 보장되지 않지만 각 파티션 내의 메시지 순서는 보장된다.
- 키Key를 통해서 데이터가 어떤 파티션으로 할당될지 결정한다. 키가 없다면 라운드로빈 방식으로 각 파티션에 할당된다.
	- `HashCode(key) % (numPartition)`
	- Custom Partitioner를 정의해서 특정 데이터를 특정 파티션에서만 처리하는 것도 가능하다. 
- 카프카 클러스터에서 토픽/파티션 수를 선택은 어떻게 해야하나? 
- 로그 보존 방법은 토픽별로 지정할 수 있다.
- 로그 보존 방법은 시간 기반 보존, 압축(동일한 키 값으로 메시지가 여러번 들어온 경우 가장 최신의 메시지만 보존하는 방법)이 있다.

## 주키퍼: 리더, 팔로워, 복제 

- 각 토픽 **파티션별로** 한 브로커가 다른 브로커의 리더로 선택된다.
- 리더는 팔로워 브로커에 토픽 파티션의 replication을 할당한다.
- 프로듀서는 리더 파티션에 레코드를 쓰고, 팔로워 파티션은 리더로부터 레코드를 읽는다.

### 아파치 주키퍼 

- 리더 브로커 선출과 토픽 복제를 추적할 수 있게 한다.
- 주키퍼는 클러스터의 브로커 중 하나를 컨트롤러로 선출한다. (리더랑 어떻게 다른거지?)
- 컨트롤러 브로커는 모든 파티션에 대한 리더,팔로워 관계를 설정한다.
- 리더와 팔로워 관계에 있는 브로커들을 ISR(In Sync Replica)라는 집합으로 본다.
- 리더 브로커에 문제가 생기면 ISR 내에 있는 브로커가 리더로 선출될 자격을 갖는다.

## 프로듀서

- 파라미터가 정말 많은거 같은데 꼭 설정해야 하는 것들은 리스트업 해두는게 좋겠다.
	- *bootstrap.servers, key.serializer, value.serializer* Producer 에게 필요한 최소 파라미터 (나머지는 디폴트로 세팅된다.)
- 프로듀서 설정 확인은 [카프카 문서](http://kafka.apache.org/documentation/#producerconfigs) 에서 확인
	- *acks* 파티션 레플리카가 얼마나 많이 레코드를 받았을 때 성공으로 볼지 설정하는 파라미터
		- acks=0 브로커에서 응답을 전혀 기다리지 않는다. 최대 throughput 달성 가능
		- acks=1 리더 리플리카가 레코드를 받는 순간 성공 응답을 보내준다.
		- acks=all in-sync replica 전부에서 레코드를 받았을 때 성공 응답을 보내준다. 레코드 유실 가능성이 가장 낮다.
	- *buffer.memory* 메세지 버퍼의 메모리 할당량 설정
	- *compression.type* = snappy / gzip / lz4 디폴트는 메세지를 압축하지 않고 보낸다.
	- *retries* 얼마나 많이 재시도 *retry.backoff.ms* 어느 시간 뒤에 재시도
	- *batch.size* 배치 사이즈(byte)
	- *linger.ms* 현재 배치에서 카프카 브로커로 메세지를 보내기전 얼마나 기다릴지 설정
	- *client.id*
	- *max.in.flight.requests.per.connection* 응답을 받지 않고 레코드를 얼마나 많이 보낼지 설정
	
- 카프카의 타임스탬프는 CreateTime 또는 LogAppendTime으로 설정할 수 있다.
	- 토픽이 브로커의 설정을 덮어쓸 수도 있다. (메서드 중에 timestamp가 파라미터로 있는 메서드를 사용하면 됨)
	- CreateTime은 이벤트시간, LogAppendTime은 처리시간으로 간주한다.
- 프로듀서에서 발생하는 에러는 재시도가능한것(Retriable)과 아닌것으로 나눌 수 있다. Retriable은 메세지를 다시 보냈을 때 해소가 가능한 경우를 뜻한다.

## 컨슈머

- 오프셋 관리 (컨슈머는 메시지의 오프셋을 커밋해 상태를 관리한다)
	- 커밋한다는 것은 컨슈머가 메시지를 완전히 처리했음을 의미한다.
	- 커밋은 실패나 재시작 시 해당 컨슈머의 시작 지점도 나타낸다.
- 설정에 따라 컨슈머가 시작하는 위치가 달라진다.
	- `auto.offset.reset="earliest"` 사용 가능한 가장 이른 오프셋부터 메시지를 가져온다.
	- `auto.offset.reset="latest"` 가장 최신 오프셋에서 메시지를 읽어서 기본적으로 컨슈머가 합류한 지점부터 유입된 메시지만 소비한다.
	- `auto.offset.reset="none"` 재설정 전략을 지정하지 않는다. 브로커가 컨슈머에 예외를 발생시킨다.
- 오프셋 커밋 옵션
	- 자동 오프셋 커밋
		- 기본값
		- `enable.auto.commit` 프로퍼티로 설정, `auto.commit.interval.ms` 는 오프셋을 커밋하는 주기 설정 너무 작으면 네트워크 트래픽을 증가시키고, 너무 길면 실패했을 때 재시작 시 컨슈머가 이미 받았던 이벤트를 다시 받을 수 있다.
- 수동 오프셋 커밋은 동기식, 비동기식 두가지 방식이 있다.
	- `consumer.commitSync()`, `consumer.commitSync(Map<TopicPartition, OffsetAndMetadata>)`
		- 첫번째는 마지막 검색에서 반환된 모든 오프셋이 성공할 때까지 블로킹
		- 두번째는 지정된 오프셋, 파티션, 토픽만 커밋한다.
	- `consumer.commitAsync()` 비동기 메서드
		- `OffsetCommitCallback` 를 통해 비동기 처리 및 오류 처리
- 컨슈머에게 토픽-파티션 할당을 추가 및 제거하는 프로세스를 리밸런싱이라 한다.

### 컨슈머 컨셉

#### 컨슈머와 컨슈머 그룹

